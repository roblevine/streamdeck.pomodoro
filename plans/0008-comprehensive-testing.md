# Comprehensive Testing Strategy

**Status:** Proposed
**Date:** 2025-11-18
**Priority:** High

## Overview

This plan establishes comprehensive automated testing for the Pomodoro Stream Deck plugin. Currently, the codebase has **zero test coverage** despite significant complexity (354-line state machine, platform-specific audio drivers, intricate user interaction patterns). This plan provides a phased approach to achieving 85%+ test coverage with fully automated, hardware-independent testing.

## Problem Statement

**Current State:**
- Zero automated tests
- Complex workflow state machine (9 states, 8 event types)
- Platform-specific code (Windows/macOS audio drivers)
- Hardware dependencies (Stream Deck SDK)
- Risk of regressions when refactoring or adding features

**Constraints:**
- Cannot use actual Stream Deck hardware in tests
- Must mock platform-specific functionality (OS audio APIs)
- Tests must run in CI/CD without external dependencies
- Must maintain backward compatibility during refactoring

## Goals

1. **Coverage Targets:**
   - Overall: 85% line coverage, 80% branch coverage
   - Core business logic (workflow.ts): 95% coverage
   - Critical components: 90% coverage

2. **Test Quality:**
   - Fast execution (<30 seconds for full suite)
   - Zero flaky tests (deterministic with fake timers)
   - Cross-platform CI/CD support

3. **Testability Improvements:**
   - Refactor for dependency injection (minimal breaking changes)
   - Abstract platform-specific code behind interfaces
   - Enable confident refactoring and feature development

## Architecture & Strategy

### Test Pyramid

```
        E2E (5%)
       /        \
      /   ~6     \
     /   tests    \
    /--------------\
   /  Integration   \
  /  (20%)  ~75     \
 /      tests        \
/--------------------\
    Unit (75%)
    ~350 tests
```

### Testing Stack

After evaluating both agent recommendations, the recommended stack is:

**Primary Framework: Vitest**
- Modern, fast, TypeScript-native
- Built-in fake timers and mocking
- Better ESM support than Jest
- Simpler configuration
- UI mode for debugging

**Alternative: Jest** (if team prefers mature ecosystem)

**Supporting Tools:**
- `@sinonjs/fake-timers` - Controllable time for timer tests
- `vitest --ui` - Visual test debugging
- Coverage via `@vitest/coverage-v8`

### Abstraction Boundaries

To enable mocking, we'll introduce these interfaces:

#### 1. Stream Deck SDK Abstraction
```typescript
// src/types/streamdeck.ts
interface IStreamDeckAction {
  id: string;
  setImage(dataUrl: string): Promise<void>;
  setTitle(title: string): Promise<void>;
  setSettings(settings: unknown): Promise<void>;
  getSettings(): Promise<unknown>;
  sendToPropertyInspector(payload: unknown): Promise<void>;
}

interface IStreamDeckLogger {
  debug(message: string, data?: unknown): void;
  info(message: string, data?: unknown): void;
  error(message: string, error?: unknown): void;
  trace(message: string, data?: unknown): void;
}
```

#### 2. Audio System Abstraction
```typescript
// src/types/audio.ts
interface IAudioPlayer {
  play(filePath: string, playbackId: string): Promise<void>;
  stop(playbackId?: string): void;
  dispose(): void;
}

interface IAudioDriver {
  init(): Promise<void>;
  play(filePath: string): Promise<void>;
  stop(): void;
  dispose(): void;
}

interface ProcessSpawner {
  spawn(command: string, args: string[]): ChildProcess;
}
```

#### 3. Timer Abstraction
```typescript
// src/types/timers.ts
interface ITimerSystem {
  setTimeout(callback: () => void, ms: number): NodeJS.Timeout;
  setInterval(callback: () => void, ms: number): NodeJS.Timeout;
  clearTimeout(timer: NodeJS.Timeout): void;
  clearInterval(timer: NodeJS.Timeout): void;
}
```

#### 4. File System Abstraction
```typescript
// src/types/filesystem.ts
interface IFileSystem {
  existsSync(path: string): boolean;
  readFileSync(path: string, encoding?: string): string | Buffer;
}
```

### Dependency Injection Pattern

**Approach:** Optional constructor parameters with defaults (backward compatible)

```typescript
// Before (tightly coupled)
class TimerManager {
  start(actionId: string, duration: number) {
    this.timers.set(actionId, setInterval(() => { ... }, 1000));
  }
}

// After (testable)
class TimerManager {
  constructor(private timerSystem: ITimerSystem = globalTimers) {}

  start(actionId: string, duration: number) {
    this.timers.set(actionId, this.timerSystem.setInterval(() => { ... }, 1000));
  }
}

// Default implementation
const globalTimers: ITimerSystem = {
  setTimeout: (cb, ms) => setTimeout(cb, ms),
  setInterval: (cb, ms) => setInterval(cb, ms),
  clearTimeout: (t) => clearTimeout(t),
  clearInterval: (t) => clearInterval(t)
};
```

**Benefits:**
- No breaking changes to existing code
- Production code continues working unchanged
- Tests inject mocks/fakes via constructor

### Test Organization

```
roblevine/
├── src/
│   ├── types/              # New: Interface definitions
│   │   ├── streamdeck.ts
│   │   ├── audio.ts
│   │   ├── filesystem.ts
│   │   └── timers.ts
│   ├── lib/
│   └── actions/
├── test/
│   ├── unit/               # Pure logic, mocked dependencies
│   │   ├── lib/
│   │   │   ├── workflow.test.ts
│   │   │   ├── workflow-controller.test.ts
│   │   │   ├── timer-manager.test.ts
│   │   │   ├── display-generator.test.ts
│   │   │   ├── pomodoro-cycle.test.ts
│   │   │   └── audio-player.test.ts
│   │   └── actions/
│   │       └── pomodoro-timer.test.ts
│   ├── integration/        # Component interactions
│   │   ├── workflow-integration.test.ts
│   │   ├── message-handlers.test.ts
│   │   └── action-lifecycle.test.ts
│   ├── e2e/                # Full user workflows
│   │   └── pomodoro-workflows.test.ts
│   ├── fixtures/           # Test data
│   │   ├── silent.wav
│   │   └── mock-settings.ts
│   ├── mocks/              # Mock implementations
│   │   ├── stream-deck.mock.ts
│   │   ├── audio.mock.ts
│   │   ├── filesystem.mock.ts
│   │   └── timers.mock.ts
│   └── helpers/            # Test utilities
│       ├── builders.ts
│       ├── assertions.ts
│       └── fake-clock.ts
├── vitest.config.ts
└── package.json
```

## Critical Test Coverage

### Highest Priority: Workflow State Machine

**Coverage Target: 95%+**

The 354-line state machine in `lib/workflow.ts` is the core of the plugin. Comprehensive testing is critical:

**Test Categories:**
1. **State Transitions** (25 tests)
   - idle → workRunning (short press)
   - workRunning → workComplete → pausedNext/nextPhase
   - pausedNext → phase running
   - pausedInFlight → phase running (resume)
   - Any state → idle (reset/long press)

2. **Pause/Resume Flow** (15 tests)
   - Pause preserves remaining time
   - Resume continues from remaining time
   - Blinking display during pause

3. **Skip/Double Press** (20 tests)
   - Skip from running work → next break
   - Skip from running break → work
   - No completion effects on skip
   - Cycle increments correctly

4. **Long Break Logic** (10 tests)
   - 4th work session → long break
   - Long break → cycle reset
   - Cycle counter updates

5. **Guard Functions** (10 tests)
   - `pauseAtEnd()` with various settings
   - `longBreakDue()` at cycle boundaries

6. **Completion Flow** (15 tests)
   - TIMER_DONE → completion animation
   - COMPLETE_ANIM_DONE → next state
   - Sound/animation triggered
   - Hold duration respected

7. **Edge Cases** (10 tests)
   - Unexpected events (no transition)
   - Settings changes mid-session
   - Context mutations

**Total: ~105 tests for workflow.ts**

### High Priority: Supporting Components

**Timer Manager** (`lib/timer-manager.ts`) - 40 tests
- Start/stop/complete lifecycle
- Multiple concurrent timers
- Tick callbacks
- Edge cases (duration=0, duration=1)

**Display Generator** (`lib/display-generator.ts`) - 50 tests
- Time formatting (0:00, 59:59, etc.)
- Arc path calculation (percentages)
- Phase colors
- SVG structure validation

**Pomodoro Cycle** (`lib/pomodoro-cycle.ts`) - 35 tests
- Duration parsing ("25:00", numeric)
- Phase transitions
- Cycle calculations

**Workflow Controller** (`lib/workflow-controller.ts`) - 60 tests
- Ports implementation
- Display updates
- Timer integration
- Settings changes

**Input Detection** (`actions/pomodoro-timer.ts`) - 35 tests
- Short vs double vs long press
- Double-press window (320ms)
- Long press watchdog (2000ms)

**Audio Player** (`lib/audio-player.ts`) - 30 tests
- Play/stop lifecycle
- Driver initialization
- File validation
- Playback ID tracking

### Medium Priority: Integration & E2E

**Integration Tests** (~75 tests)
- Full timer cycles with mocked dependencies
- Message handler flows
- Action lifecycle (appear/disappear)

**E2E Workflows** (~6 comprehensive scenarios)
- Complete 4-work-session cycle
- Pause/resume workflow
- Skip workflow
- Reset workflow
- Settings change workflow
- Multi-instance workflow

## Implementation Phases

### Phase 0: Foundation (2-3 days)

**Goal:** Establish testing infrastructure

**Tasks:**
1. Install Vitest and dependencies
   ```bash
   npm install -D vitest @vitest/ui @vitest/coverage-v8 @sinonjs/fake-timers
   ```

2. Create `vitest.config.ts`:
   ```typescript
   import { defineConfig } from 'vitest/config';

   export default defineConfig({
     test: {
       globals: true,
       environment: 'node',
       include: ['test/**/*.test.ts'],
       coverage: {
         provider: 'v8',
         reporter: ['text', 'html', 'lcov'],
         exclude: ['test/**', 'src/plugin.ts'],
         thresholds: {
           lines: 85,
           branches: 80,
           functions: 90
         }
       }
     }
   });
   ```

3. Add npm scripts to `package.json`:
   ```json
   {
     "scripts": {
       "test": "vitest run",
       "test:watch": "vitest",
       "test:ui": "vitest --ui",
       "test:coverage": "vitest run --coverage"
     }
   }
   ```

4. Create test directory structure (as outlined above)

5. Create helper utilities:
   - `test/mocks/stream-deck.mock.ts` - Mock Stream Deck action
   - `test/mocks/audio.mock.ts` - Mock audio player/driver
   - `test/helpers/fake-clock.ts` - Controllable timer system
   - `test/fixtures/silent.wav` - Minimal fixture file

6. Verify setup with one trivial test

**Deliverables:**
- Working Vitest configuration
- Test infrastructure ready
- Helper utilities available

**Success Criteria:**
- `npm test` runs successfully
- Coverage report generates
- Watch mode functional

---

### Phase 1: Core Logic Unit Tests (4-5 days)

**Goal:** Test pure business logic (highest ROI)

**Priority Order:**

#### 1.1 Display Generator Tests (Day 1 - 4 hours)
**File:** `test/unit/lib/display-generator.test.ts`

**Why First:** Zero dependencies, pure functions, quick wins

**Test Cases:** ~50 tests
- `formatTime()` with edge cases (0, 59, 60, 3599, 3661)
- `calculateArcPath()` percentages (0, 0.25, 0.5, 0.75, 1.0)
- `getPhaseColor()` for all phases
- SVG generation functions
- `svgToDataUrl()` encoding

**Value:** Immediate confidence in visual rendering

#### 1.2 Pomodoro Cycle Tests (Day 1 - 3 hours)
**File:** `test/unit/lib/pomodoro-cycle.test.ts`

**Test Cases:** ~35 tests
- `parseDuration()` variations
- `getDurationForPhase()` for all phases
- `getNextPhase()` transition matrix
  - work → shortBreak (cycles 1-3)
  - work → longBreak (cycle 4)
  - shortBreak → work
  - longBreak → work

**Value:** Ensures cycle calculations are correct

#### 1.3 Timer Manager Tests (Days 2-3 - 6 hours)
**File:** `test/unit/lib/timer-manager.test.ts`

**Refactoring Required:**
- Add optional `timerSystem: ITimerSystem` parameter to constructor
- Default to global `setTimeout`/`setInterval`

**Test Cases:** ~40 tests
- Start → onTick called every second
- Duration expires → onComplete called
- Stop clears interval
- Multiple concurrent timers (different actionIds)
- Edge cases: duration=0, duration=1
- Timer restart (previous stopped)

**Test Pattern:**
```typescript
import { describe, it, expect, beforeEach } from 'vitest';
import { FakeClock } from '../../helpers/fake-clock';
import { TimerManager } from '../../../src/lib/timer-manager';

describe('TimerManager', () => {
  let clock: FakeClock;
  let manager: TimerManager;

  beforeEach(() => {
    clock = new FakeClock();
    manager = new TimerManager(clock);
  });

  it('should call onTick every second', () => {
    const ticks: number[] = [];
    manager.start('action1', 5, {
      onTick: (remaining) => ticks.push(remaining),
      onComplete: () => {}
    });

    clock.tick(1000);
    expect(ticks).toEqual([4]);

    clock.tick(1000);
    expect(ticks).toEqual([4, 3]);
  });
});
```

**Value:** Critical for reliable countdown behavior

#### 1.4 Workflow State Machine Tests (Days 3-5 - 12-15 hours)
**File:** `test/unit/lib/workflow.test.ts`

**Test Cases:** ~105 tests (comprehensive coverage)

**Categories:**
1. Guard functions (10 tests)
2. Basic transitions (25 tests)
3. Pause/resume (15 tests)
4. Skip/double-press (20 tests)
5. Long break logic (10 tests)
6. Completion flow (15 tests)
7. Edge cases (10 tests)

**Test Pattern:**
```typescript
import { describe, it, expect } from 'vitest';
import { createWorkflow, Ports } from '../../../src/lib/workflow';
import { MockPorts } from '../../mocks/ports.mock';

describe('Workflow State Machine', () => {
  let ports: MockPorts;
  let workflow: ReturnType<typeof createWorkflow>;

  beforeEach(() => {
    ports = new MockPorts();
    workflow = createWorkflow(ports, {
      workDuration: 25,
      shortBreakDuration: 5,
      longBreakDuration: 15,
      cyclesBeforeLongBreak: 4,
      pauseAtEndOfEachTimer: true,
      enableSound: false
    });
  });

  describe('Basic transitions', () => {
    it('should transition from idle to workRunning on SHORT_PRESS', () => {
      expect(workflow.state).toBe('idle');

      workflow.dispatch({ type: 'SHORT_PRESS' });

      expect(workflow.state).toBe('workRunning');
      expect(ports.startTimer).toHaveBeenCalledWith(25 * 60);
    });
  });

  describe('Pause/resume', () => {
    it('should preserve remaining time when pausing', () => {
      workflow.dispatch({ type: 'SHORT_PRESS' }); // idle → workRunning

      // Simulate timer tick
      workflow.ctx.remaining = 300; // 5 minutes left
      workflow.dispatch({ type: 'SHORT_PRESS' }); // pause

      expect(workflow.state).toBe('pausedInFlight');
      expect(workflow.ctx.remaining).toBe(300);
    });
  });
});
```

**Value:** Highest complexity, highest risk - comprehensive coverage essential

**Phase 1 Deliverables:**
- ~230 passing unit tests
- 95%+ coverage on core logic
- Foundation for subsequent phases
- Confidence in display, timers, cycles, and state machine

**Phase 1 Success Criteria:**
- All tests pass
- Tests run in <5 seconds
- Coverage report shows green for core components

---

### Phase 2: Component Unit Tests (3-4 days)

**Goal:** Test components with mocked dependencies

#### 2.1 Audio Player Tests (Day 1 - 4 hours)
**File:** `test/unit/lib/audio-player.test.ts`

**Refactoring Required:**
- Mock `fs` module
- Add `ProcessSpawner` interface to audio drivers (optional parameter)

**Test Cases:** ~30 tests
- `play()` initializes driver on first call
- `play()` calls driver.play(filePath)
- `play()` stops previous playback
- File validation (non-existent file)
- `stop()` with playbackId match/mismatch
- `dispose()` cleanup
- Error handling

**Test Pattern:**
```typescript
import { describe, it, expect, vi } from 'vitest';
import { AudioPlayer } from '../../../src/lib/audio-player';
import { MockAudioDriver } from '../../mocks/audio.mock';

vi.mock('node:fs', () => ({
  existsSync: vi.fn(() => true)
}));

describe('AudioPlayer', () => {
  it('should stop previous playback when playing new sound', async () => {
    const driver = new MockAudioDriver();
    const player = new AudioPlayer(() => driver);

    await player.play('sound1.wav', 'id1');
    await player.play('sound2.wav', 'id2');

    expect(driver.stopCallCount).toBe(1);
    expect(driver.playedFiles).toEqual(['sound1.wav', 'sound2.wav']);
  });
});
```

#### 2.2 Workflow Controller Tests (Days 1-3 - 8-10 hours)
**File:** `test/unit/lib/workflow-controller.test.ts`

**Test Cases:** ~60 tests

**Categories:**
1. Initialization (8 tests)
   - `init()` creates workflow
   - `appear()` fresh vs existing
   - Controller reuse

2. Ports implementation (20 tests)
   - `showFull()` generates SVG
   - `updateRunning()` updates display
   - `showPaused()` starts blink
   - `showCompletionWithSound()` animation + audio
   - `showResetFeedback()` flash + sound
   - `startTimer()`/`stopTimer()`

3. Input handling (12 tests)
   - `shortPress()` dispatches event
   - `longPress()` dispatches + resets
   - `doublePress()` dispatches

4. Settings integration (10 tests)
   - `settingsChanged()` updates context
   - Duration changes
   - pauseAtEndOfEachTimer toggle

5. Remaining time computation (8 tests)

**Test Pattern:**
```typescript
import { describe, it, expect, vi } from 'vitest';
import { WorkflowController } from '../../../src/lib/workflow-controller';
import { MockStreamDeckAction } from '../../mocks/stream-deck.mock';
import { MockTimerManager } from '../../mocks/timer-manager.mock';
import { FakeClock } from '../../helpers/fake-clock';

describe('WorkflowController', () => {
  it('should update display when timer ticks', async () => {
    const action = new MockStreamDeckAction();
    const clock = new FakeClock();
    const controller = new WorkflowController(
      action,
      { timerSystem: clock }
    );

    await controller.init(mockSettings);
    controller.shortPress();

    // Simulate tick
    controller.updateRunning(1500); // 25:00 remaining

    expect(action.setImageCalls.length).toBe(2); // initial + tick
    expect(action.lastImage).toContain('25:00');
  });
});
```

#### 2.3 Input Detection Tests (Day 4 - 6 hours)
**File:** `test/unit/actions/pomodoro-timer.test.ts`

**Test Cases:** ~35 tests
- Short press detection (keyDown → keyUp → 320ms delay)
- Double press (two taps within 320ms)
- Long press (keyDown held 2000ms)
- Long press watchdog
- Key click sound on keyDown
- Settings normalization

**Test Pattern:**
```typescript
import { describe, it, expect } from 'vitest';
import { FakeClock } from '../../helpers/fake-clock';
import { PomodoroTimer } from '../../../src/actions/pomodoro-timer';
import { MockStreamDeckAction } from '../../mocks/stream-deck.mock';

describe('Input Detection', () => {
  it('should detect double press within 320ms', () => {
    const clock = new FakeClock();
    const action = new MockStreamDeckAction();
    const timer = new PomodoroTimer({ timerSystem: clock });
    const dispatchSpy = vi.fn();

    // First tap
    timer.onKeyDown();
    clock.tick(100);
    timer.onKeyUp();

    // Second tap within window
    clock.tick(100);
    timer.onKeyDown();
    clock.tick(100);
    timer.onKeyUp();

    // Should dispatch DOUBLE_PRESS immediately
    expect(timer.lastDispatchedEvent).toBe('DOUBLE_PRESS');
  });
});
```

**Phase 2 Deliverables:**
- ~125 additional tests (~355 total)
- Coverage on audio, controller, input components
- Mock implementations refined

---

### Phase 3: Integration Tests (3-4 days)

**Goal:** Test component interactions with realistic scenarios

#### 3.1 Workflow + Controller + Timer Integration (Days 1-2 - 8 hours)
**File:** `test/integration/workflow-integration.test.ts`

**Test Scenarios:** ~40 tests

**Categories:**
1. Complete timer cycle (10 tests)
   - Start → tick → complete → pausedNext
   - Resume → next phase → complete
   - Long break after 4th cycle

2. Pause/resume flow (8 tests)
   - Pause preserves remaining
   - Resume continues correctly
   - Display blinks during pause

3. Skip integration (6 tests)
   - Double-press during work
   - Double-press during break
   - Cycle increments

4. Reset integration (5 tests)
   - Long press → idle
   - Reset feedback
   - Cycle reset

5. Display updates (8 tests)
   - Running updates
   - Pause updates
   - Completion updates

**Test Pattern:**
```typescript
import { describe, it, expect } from 'vitest';
import { createWorkflow } from '../../../src/lib/workflow';
import { WorkflowController } from '../../../src/lib/workflow-controller';
import { TimerManager } from '../../../src/lib/timer-manager';
import { FakeClock } from '../../helpers/fake-clock';

describe('Workflow Integration', () => {
  it('should complete full work cycle', () => {
    const clock = new FakeClock();
    const action = new MockStreamDeckAction();
    const controller = new WorkflowController(action, { timerSystem: clock });

    controller.init(mockSettings);
    controller.shortPress(); // Start work

    expect(workflow.state).toBe('workRunning');

    // Fast-forward 25 minutes
    clock.tick(25 * 60 * 1000);

    expect(workflow.state).toBe('pausedNext');
    expect(workflow.ctx.pendingNext).toBe('shortBreak');
    expect(action.lastImage).toContain('completion animation');
  });
});
```

#### 3.2 Message Handler Integration (Day 2 - 4 hours)
**File:** `test/integration/message-handlers.test.ts`

**Test Cases:** ~20 tests
- Preview sound flow
- Stop sound flow
- playbackStarted/Stopped responses
- Error handling
- Multiple handlers

#### 3.3 Action Lifecycle Integration (Day 3 - 5 hours)
**File:** `test/integration/action-lifecycle.test.ts`

**Test Cases:** ~20 tests
- onWillAppear (fresh)
- onWillAppear (existing context)
- onWillDisappear (state preserved)
- Settings changes
- Multi-instance independence

**Phase 3 Deliverables:**
- ~80 integration tests (~435 total)
- Full component interaction coverage

---

### Phase 4: End-to-End Workflows (2-3 days)

**Goal:** Validate complete user workflows

**File:** `test/e2e/pomodoro-workflows.test.ts`

**Test Scenarios:** 6 comprehensive workflows

#### 4.1 Complete Pomodoro Cycle (Day 1 - 3 hours)
- 4 work sessions + 3 short breaks + 1 long break
- Verify cycle counter updates
- Verify phase colors correct
- Verify all completion effects

#### 4.2 Pause/Resume Workflow (Day 1 - 1.5 hours)
- Start work → pause mid-timer → resume → complete

#### 4.3 Skip Workflow (Day 1 - 1 hour)
- Double-press to skip phases without completion

#### 4.4 Reset Workflow (Day 2 - 1 hour)
- Long-press reset mid-cycle

#### 4.5 Configuration Change Workflow (Day 2 - 1.5 hours)
- Change settings mid-session
- Verify next cycle uses new settings

#### 4.6 Multi-Instance Workflow (Day 2 - 1 hour)
- Two actions with independent timers

**Test Pattern:**
```typescript
import { describe, it, expect } from 'vitest';
import { setupFullPlugin } from '../../helpers/setup';

describe('E2E: Complete Pomodoro Cycle', () => {
  it('should complete 4 work sessions with breaks and long break', () => {
    const { action, controller, clock } = setupFullPlugin({
      workDuration: 25,
      shortBreakDuration: 5,
      longBreakDuration: 15,
      cyclesBeforeLongBreak: 4
    });

    // Cycle 1: Work + Short Break
    controller.shortPress(); // Start work
    expect(action.lastImage).toContain('25:00');

    clock.tick(25 * 60 * 1000); // Complete work
    expect(action.lastImage).toContain('completion');

    controller.shortPress(); // Start short break
    clock.tick(5 * 60 * 1000); // Complete break

    // ... repeat for cycles 2-3 ...

    // Cycle 4: Work + Long Break
    controller.shortPress(); // Start work 4
    clock.tick(25 * 60 * 1000);

    controller.shortPress(); // Start long break
    expect(action.lastImage).toContain('15:00');
    clock.tick(15 * 60 * 1000);

    // Cycle should reset
    expect(workflow.ctx.cycleIndex).toBe(0);
  });
});
```

**Phase 4 Deliverables:**
- 6 comprehensive E2E tests
- Full user workflow validation
- ~440 total tests

---

### Phase 5: Platform-Specific & Edge Cases (2-3 days)

**Goal:** Test platform-specific drivers and edge cases

#### 5.1 Audio Driver Tests (Days 1-2 - 5 hours)
**Files:**
- `test/unit/lib/audio-driver/windows-persistent.test.ts`
- `test/unit/lib/audio-driver/macos-system.test.ts`

**Refactoring Required:**
- Add optional `ProcessSpawner` parameter to driver constructors

**Test Cases:** ~30 tests

**Windows Driver:**
- PowerShell command construction
- PLAYB64/STOP/EXIT commands
- Persistent process management
- Error handling

**macOS/Linux Driver:**
- afplay/aplay command spawning
- SIGKILL on stop
- Error handling

**Test Pattern:**
```typescript
import { describe, it, expect, vi } from 'vitest';
import { WindowsPersistentDriver } from '../../../src/lib/audio-driver/windows-persistent';
import { MockProcessSpawner } from '../../mocks/process-spawner.mock';

describe('WindowsPersistentDriver', () => {
  it('should spawn PowerShell process once', async () => {
    const spawner = new MockProcessSpawner();
    const driver = new WindowsPersistentDriver(spawner);

    await driver.init();
    await driver.play('sound1.wav');
    await driver.play('sound2.wav');

    expect(spawner.spawnCallCount).toBe(1);
    expect(spawner.lastCommand).toBe('powershell.exe');
  });
});
```

#### 5.2 Edge Case Tests (Days 2-3 - 6 hours)
**Various test files**

**Test Cases:** ~30 tests

**Categories:**
1. Timing edge cases (10 tests)
   - Triple-press sequence
   - Long press interrupted at 1999ms
   - Timer duration=0, duration=1
   - Completion hold duration edge cases

2. Audio edge cases (8 tests)
   - File deleted mid-session
   - Driver init fails
   - Concurrent playback
   - Multiple dispose calls

3. State machine edge cases (8 tests)
   - Unexpected events
   - Settings changes during states
   - Context edge values

4. Display edge cases (4 tests)
   - Percentage boundary values
   - Negative remaining (defensive)
   - Blink timer cleanup

**Phase 5 Deliverables:**
- ~60 additional tests (~500 total)
- Platform-specific coverage
- Comprehensive edge case handling

---

## Summary: Implementation Timeline

| Phase | Duration | Tests Added | Cumulative Tests | Key Deliverables |
|-------|----------|-------------|------------------|------------------|
| Phase 0 | 2-3 days | 1 (verify) | 1 | Testing infrastructure, mocks, helpers |
| Phase 1 | 4-5 days | ~230 | ~230 | Core logic coverage (display, cycle, timer, workflow) |
| Phase 2 | 3-4 days | ~125 | ~355 | Component coverage (audio, controller, input) |
| Phase 3 | 3-4 days | ~80 | ~435 | Integration tests (full component interactions) |
| Phase 4 | 2-3 days | ~6 | ~440 | E2E workflows (user scenarios) |
| Phase 5 | 2-3 days | ~60 | ~500 | Platform-specific drivers, edge cases |
| **Total** | **16-22 days** | **~500** | **~500** | **85%+ coverage, production-ready test suite** |

## Refactoring Requirements

### Minimal Breaking Changes Required

All refactoring maintains backward compatibility via optional parameters with defaults:

1. **TimerManager** (`lib/timer-manager.ts`)
   ```typescript
   // Add optional parameter
   constructor(private timerSystem: ITimerSystem = globalTimers) {}
   ```

2. **Audio Drivers** (`lib/audio-driver/*.ts`)
   ```typescript
   // Add optional parameter
   constructor(private spawner: ProcessSpawner = child_process) {}
   ```

3. **WorkflowController** (already dependency-friendly via Ports)
   - No changes needed; Ports interface already supports mocking

4. **Interface Definitions** (new files)
   - Create `src/types/*.ts` files
   - No changes to existing code

**Total Code Changes:** ~10 lines of optional parameters across 3 files

## Quality Metrics & CI/CD

### Coverage Targets (Enforced by Vitest)

```typescript
// vitest.config.ts
coverage: {
  thresholds: {
    lines: 85,
    branches: 80,
    functions: 90
  }
}
```

### Performance Targets

- Unit tests: <5 seconds
- Integration tests: <15 seconds
- Full suite: <30 seconds
- CI pipeline: <3 minutes

### CI/CD Integration

**GitHub Actions Workflow:**

```yaml
# .github/workflows/test.yml
name: Test

on: [push, pull_request]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        node: ['20.x']
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node }}
      - run: npm ci
      - run: npm test
      - run: npm run test:coverage
      - uses: codecov/codecov-action@v3
        if: matrix.os == 'ubuntu-latest'
        with:
          files: ./coverage/lcov.info
```

**Benefits:**
- Tests run on every commit/PR
- Cross-platform validation
- Coverage tracking over time
- Prevents regressions

## Risk Analysis & Mitigation

### Risk 1: Time Investment (16-22 days)

**Mitigation:**
- Phased approach delivers value incrementally
- Phase 1 alone provides 230 tests covering core logic
- Can pause after any phase for assessment

### Risk 2: Flaky Tests

**Cause:** Real timers in tests

**Mitigation:**
- Mandatory use of fake timers (FakeClock)
- No `sleep()` or real `setTimeout()` in tests
- Deterministic test execution

### Risk 3: Mock Accuracy

**Cause:** Mocks may not match real behavior

**Mitigation:**
- Mocks based on actual interfaces
- Integration tests validate real component interactions
- Manual testing on real hardware for major releases
- Document mock limitations

### Risk 4: Maintenance Burden

**Mitigation:**
- Keep tests focused and minimal
- Delete obsolete tests promptly
- Refactor tests alongside code
- CI enforces test passing

## Success Criteria

### Quantitative
- ✅ 85%+ line coverage
- ✅ 80%+ branch coverage
- ✅ 90%+ function coverage
- ✅ 500+ passing tests
- ✅ <30 second test suite runtime
- ✅ Zero flaky tests

### Qualitative
- ✅ Developers can refactor workflow.ts confidently
- ✅ State machine changes validated automatically
- ✅ Platform-specific issues isolated
- ✅ Regressions caught before release
- ✅ Tests serve as living documentation

## Next Steps (Awaiting Approval)

This plan proposes a comprehensive 5-phase testing strategy. I recommend starting with:

### Proposed Initial Scope: Phase 0 + Phase 1

**Duration:** 6-8 days
**Deliverables:**
- Complete testing infrastructure
- ~230 unit tests for core logic
- 95%+ coverage on workflow.ts, display-generator.ts, pomodoro-cycle.ts, timer-manager.ts

**Value:**
- Immediate confidence in critical components
- Foundation for subsequent phases
- Enables confident refactoring
- Demonstrates ROI of testing investment

**Approval Requested For:**
1. Install Vitest and testing dependencies
2. Create test infrastructure (config, mocks, helpers)
3. Implement Phase 0 + Phase 1 tests
4. Make minimal refactorings for testability:
   - Optional `timerSystem` parameter to TimerManager
   - Interface definitions in `src/types/`

**No changes to production functionality** - only adding tests and optional dependency injection.

After Phase 1 completion, I will:
- Provide coverage report
- Demonstrate tests in watch mode
- Recommend Phase 2 priorities based on gaps

---

**Ready to proceed with Phase 0 + Phase 1?** Please review and approve to begin implementation.
